{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Binarizer, Imputer, \\\n",
    "    OneHotEncoder, PolynomialFeatures, StandardScaler, \\\n",
    "    MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15.0</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex   age address famsize Pstatus  Medu  Fedu     Mjob      Fjob ...  \\\n",
       "0     GP   F  18.0       U     GT3       A     4     4  at_home   teacher ...   \n",
       "1     GP   F  15.0       U     LE3       T     1     1  at_home     other ...   \n",
       "2     GP   F   NaN       U     GT3       T     4     2   health  services ...   \n",
       "3     GP   F  16.0       U     GT3       T     3     3    other     other ...   \n",
       "4     GP   F   NaN       U     GT3       A     4     4    other   teacher ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1    G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6.0   6  \n",
       "1      4        3      2     2     3      3       10   7   8.0  10  \n",
       "2      3        2      2     1     1      5        2  15   NaN  15  \n",
       "3      4        3      2     1     2      5        4   6  10.0  10  \n",
       "4      4        1      4     1     1      1        6   6   5.0   6  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set comes from the [Student Performance](http://archive.ics.uci.edu/ml/datasets/Student+Performance) dataset at the University of Calforina at Irvine Machine Learning Repository. It details student performance in schools in Portugal as regards to mathematics. It contains the following features:\n",
    "\n",
    "- school - student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira)\n",
    "- sex - student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "- age - student's age (numeric: from 15 to 22)\n",
    "- address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "- famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "- Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "- Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "- Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "- Mjob - mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "- Fjob - father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "- reason - reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "- guardian - student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "- traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "- studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "- failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "- schoolsup - extra educational support (binary: yes or no)\n",
    "- famsup - family educational support (binary: yes or no)\n",
    "- paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "- activities - extra-curricular activities (binary: yes or no)\n",
    "- nursery - attended nursery school (binary: yes or no)\n",
    "- higher - wants to take higher education (binary: yes or no)\n",
    "- internet - Internet access at home (binary: yes or no)\n",
    "- romantic - with a romantic relationship (binary: yes or no)\n",
    "- famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "- freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "- goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "- Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "- Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "- health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "- absences - number of school absences (numeric: from 0 to 93)\n",
    "- G1 - first period grade (numeric: from 0 to 20)\n",
    "- G2 - second period grade (numeric: from 0 to 20)\n",
    "- G3 - final grade (numeric: from 0 to 20, output target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>16.0</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex   age address famsize Pstatus  Medu  Fedu      Mjob   Fjob ...  \\\n",
       "0     GP   F  17.0       U     GT3       T     1     1   at_home  other ...   \n",
       "1     GP   M   NaN       U     LE3       T     4     3  services  other ...   \n",
       "2     GP   M  16.0       U     LE3       T     2     2     other  other ...   \n",
       "3     GP   M  15.0       U     GT3       T     3     4     other  other ...   \n",
       "4     GP   F   NaN       U     GT3       T     2     1  services  other ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1    G2  G3  \n",
       "0      5        3      3     1     1      3        4   5   5.0   6  \n",
       "1      5        4      2     1     2      5       10  15  15.0  15  \n",
       "2      4        4      4     1     1      3        0  12  12.0  11  \n",
       "3      5        5      1     1     1      5        0  14  15.0  15  \n",
       "4      5        2      2     1     1      4        4  10  12.0  12  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.reshape(-1, 1)`???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn has become fairly strict over the years about the shape of the numpy arrays / pandas dataframes that it will accept for certain situations. Let's walk through a couple of these transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pd.DataFrame().values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.values` on a Pandas dataframe returns the underlying `numpy` array. On a 2D dataframe (with a set of columns), we get an array that has the expected shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\n",
      " (190, 2) \n",
      " first five rows:\n",
      " [[  5.   6.]\n",
      " [  7.   8.]\n",
      " [ 15.  nan]\n",
      " [  6.  10.]\n",
      " [  6.   5.]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = df[['G1', 'G2']].values\n",
    "print('shape:\\n', numpy_array.shape, '\\n',\n",
    "      'first five rows:\\n', numpy_array[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we receive an array of arrays. \n",
    "\n",
    "This is the typical shape that `sklearn` expects from `numpy`:\n",
    "  - Each row is its own array\n",
    "  - The shape should be (number of rows, number of columns)\n",
    "  \n",
    "However, look at what happens when we call `.values` from Pandas on one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\n",
      " (190,) \n",
      " first five elements:\n",
      " [ 5  7 15  6  6]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = df['G1'].values\n",
    "print('shape:\\n', numpy_array.shape, '\\n',\n",
    "      'first five elements:\\n', numpy_array[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a **1 Dimensional Array** that `sklearn` will interpret as a single _row_ of data with 190 elements.\n",
    "\n",
    "We want `sklearn` to interpret that data, however, as **190 rows** of **one element each**. There are two ways to do this:\n",
    "\n",
    "#### Coercion in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\n",
      " (190, 1) \n",
      " first five elements:\n",
      " [[ 5]\n",
      " [ 7]\n",
      " [15]\n",
      " [ 6]\n",
      " [ 6]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = df[['G1']].values\n",
    "print('shape:\\n', numpy_array.shape, '\\n',\n",
    "      'first five elements:\\n', numpy_array[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always enclosing the single column name in `[]` (so that there are two sets of `[]` will force the column to have **190 rows** and **one element per row**\n",
    "\n",
    "#### Using `numpy`'s reshape to do it after the fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\n",
      " (190, 1) \n",
      " first five elements:\n",
      " [[ 5]\n",
      " [ 7]\n",
      " [15]\n",
      " [ 6]\n",
      " [ 6]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = df['G1'].values.reshape(-1, 1)\n",
    "print('shape:\\n', numpy_array.shape, '\\n',\n",
    "      'first five elements:\\n', numpy_array[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `numpy`'s reshape command to coerce the array to have the maximum possible value (`-1`) for the number of rows and `1` element per row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using the latter (`df['G1'].values.reshape(-1, 1)`) but you should feel free to use either. **However** not doing this can lead to strange behavior on the part of `sklearn`, so make sure that you are doing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining `numpy` arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For parts of the following lesson and lab, knowing how to join numpy arrays may be helpful. Here is a quick tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 1) (190, 1)\n"
     ]
    }
   ],
   "source": [
    "array_1 = df[['G1']].values\n",
    "array_2 = df[['G2']].values\n",
    "print(array_1.shape, array_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we should check that our arrays have the same size!\n",
    "\n",
    "Next we'll use numpy's `concatenate` method to join the two arrays together. This is very similar to using Panda's `concat` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 2)\n",
      "[[  5.   6.]\n",
      " [  7.   8.]\n",
      " [ 15.  nan]\n",
      " [  6.  10.]\n",
      " [  6.   5.]]\n"
     ]
    }
   ],
   "source": [
    "array_3 = np.concatenate([array_1, array_2], axis=1)\n",
    "print(array_3.shape)\n",
    "print(array_3[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.concatenate` takes a list of arrays and the axis to add the new values to. \n",
    "\n",
    "#### Axis values\n",
    "\n",
    "- `axis=0`: create new rows for the values (join to the bottom of the array)\n",
    "- `axis=1`: create new columns for the values (join to the right of the array)\n",
    "\n",
    "Because we want to join them so that we have _new_ columns but the same number of row, we'll choose to join them on the second axis (columns, i.e., `axis=1`). Typically we will want to choose `axis=1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarizer will return a numpy array with a dummy variable based on a cutoff you give it.\n",
    "\n",
    "Let's assume that we want to create a dummy variable based on whether `G1` is above the midpoint (10). \n",
    "\n",
    "We would do that in the following way (remembering to **fit** once and **transform** multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]] [[ 5]\n",
      " [ 7]\n",
      " [15]\n",
      " [ 6]\n",
      " [ 6]] 0.473684210526\n"
     ]
    }
   ],
   "source": [
    "g1_binarizer = Binarizer(10)\n",
    "g1_binarizer.fit(df['G1'].values.reshape(-1,1))\n",
    "g1_grades = g1_binarizer.transform(\n",
    "    df['G1'].values.reshape(-1, 1))\n",
    "print(g1_grades[0:5],\n",
    "      df['G1'].values.reshape(-1,1)[0:5],\n",
    "      g1_grades.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how this applies to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]] 0.546341463415\n"
     ]
    }
   ],
   "source": [
    "g1_grades_test = g1_binarizer.transform(\n",
    "    test_df['G1'].values.reshape(-1, 1))\n",
    "print(g1_grades_test[0:5], g1_grades_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `absences` feature in the dataframe holds the number of absences that the student has faced. We would like to create a dummy variable for \"high number of absences.\" Please try the following:\n",
    "\n",
    "1. Use some EDA on the training data (`df`) to determine what is a \"high number\" of absences\n",
    "    - Note, this is left deliberately vague. As a data scientist, it is up to you to decide what \"high\" may mean in this context.\n",
    "2. Instantiate (create) a `Binarizer` object at that number\n",
    "3. Fit it to the training data and then transform the training data. What shape is the transformed training feature? What is the mean of your new column? \n",
    "4. Transform the same feature in your test data. What is the shape of the transformed test feature? Does it have a similar mean to your training feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]] [[ 6]\n",
      " [10]\n",
      " [ 2]\n",
      " [ 4]\n",
      " [ 6]] 0.221052631579\n"
     ]
    }
   ],
   "source": [
    "absences_binarizer = Binarizer(10)\n",
    "absences_binarizer.fit(df['absences'].values.reshape(-1,1))\n",
    "absences_grades = absences_binarizer.transform(\n",
    "    df['absences'].values.reshape(-1, 1))\n",
    "print(absences_grades[0:5],\n",
    "      df['absences'].values.reshape(-1,1)[0:5],\n",
    "      absences_grades.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has some missing values in the `age` and `G2` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 190 entries, 0 to 189\n",
      "Data columns (total 33 columns):\n",
      "school        190 non-null object\n",
      "sex           190 non-null object\n",
      "age           147 non-null float64\n",
      "address       190 non-null object\n",
      "famsize       190 non-null object\n",
      "Pstatus       190 non-null object\n",
      "Medu          190 non-null int64\n",
      "Fedu          190 non-null int64\n",
      "Mjob          190 non-null object\n",
      "Fjob          190 non-null object\n",
      "reason        190 non-null object\n",
      "guardian      190 non-null object\n",
      "traveltime    190 non-null int64\n",
      "studytime     190 non-null int64\n",
      "failures      190 non-null int64\n",
      "schoolsup     190 non-null object\n",
      "famsup        190 non-null object\n",
      "paid          190 non-null object\n",
      "activities    190 non-null object\n",
      "nursery       190 non-null object\n",
      "higher        190 non-null object\n",
      "internet      190 non-null object\n",
      "romantic      190 non-null object\n",
      "famrel        190 non-null int64\n",
      "freetime      190 non-null int64\n",
      "goout         190 non-null int64\n",
      "Dalc          190 non-null int64\n",
      "Walc          190 non-null int64\n",
      "health        190 non-null int64\n",
      "absences      190 non-null int64\n",
      "G1            190 non-null int64\n",
      "G2            134 non-null float64\n",
      "G3            190 non-null int64\n",
      "dtypes: float64(2), int64(14), object(17)\n",
      "memory usage: 49.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    43\n",
       "G2     56\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up an `Imputer` object to fill in the missing values for `age`. We'll start by deciding whether the mean, median, or most frequent value is the best option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    147.000000\n",
       "mean      16.659864\n",
       "std        1.268677\n",
       "min       15.000000\n",
       "25%       16.000000\n",
       "50%       17.000000\n",
       "75%       18.000000\n",
       "max       19.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([ 16.]), count=array([40]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "mode(df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results are as follows:\n",
    "\n",
    "- Mean: 16.65\n",
    "- Median: 17\n",
    "- Mode: 16.0\n",
    "\n",
    "What is most appropriate? Check in on Slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.]\n",
      " [ 15.]\n",
      " [ 17.]\n",
      " [ 16.]\n",
      " [ 17.]] 16.7368421053\n"
     ]
    }
   ],
   "source": [
    "strategy = 'median' # We'll fill this in based on class response!\n",
    "\n",
    "age_imputer = Imputer(strategy=strategy)\n",
    "age_imputer.fit(df['age'].values.reshape(-1, 1))\n",
    "\n",
    "ages = age_imputer.transform(\n",
    "    df['age'].values.reshape(-1, 1))\n",
    "print(ages[0:5], ages.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_imputer.statistics_ # returns the value that it will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this to the test df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-transform mean: 16.683870967741935\n",
      "[[ 17.]\n",
      " [ 17.]\n",
      " [ 16.]\n",
      " [ 15.]\n",
      " [ 17.]] 16.7609756098\n"
     ]
    }
   ],
   "source": [
    "print('pre-transform mean:', test_df['age'].mean())\n",
    "test_age_pre = test_df['age'].values.reshape(-1, 1)\n",
    "\n",
    "test_age_post = age_imputer.transform(test_age_pre)\n",
    "print(test_age_post[0:5], test_age_post.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Understanding\n",
    "\n",
    "The `G2` feature in the dataframe holds the grades at the second check-in for the students. We would like to fill in the missing values present in the data. Please try the following:\n",
    "\n",
    "1. Use some EDA on the training data (df) to determine whether the most frequent number, the mean, or the median would be the \"best\" value to fill in.\n",
    "    - Note, this is left deliberately vague. As a data scientist, it is up to you to decide what \"the best\" value is. Is staying close to the average value most important? Is looking like other students most important? Are there measures that are similar?\n",
    "2. Instantiate (create) an `Imputer` object with that strategy\n",
    "3. Fit it to the training data and then transform the training data. What shape is the transformed training feature? What is the mean of your new column? How does it compare to the distribution of that feature before you filled in the nulls?\n",
    "4. Transform the same feature in your test data. What is the shape of the transformed test feature? Does it have a similar mean to your training feature? \n",
    "5. Should you use the values in the holdout (test) set to inform what the \"best\" value to impute is? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `PolynomialFeatures` a little less frequently than other preprocessing libraries. However, it can be useful to add a $\\text{term}^2$ term to our linear models to capture non-linear effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.   36.]\n",
      " [  10.  100.]\n",
      " [  15.  225.]\n",
      " [  10.  100.]\n",
      " [   6.   36.]]\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(2, include_bias=False)\n",
    "poly_features.fit(df['G3'].values.reshape(-1, 1))\n",
    "\n",
    "age_and_age_squared = poly_features.transform(\n",
    "    df['G3'].values.reshape(-1, 1))\n",
    "\n",
    "print(age_and_age_squared[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Understanding (15-20 minutes)\n",
    "\n",
    "Working together in a group or pair, answer the following questions. Questions 1-3 refers to the following \"model\":\n",
    "\n",
    "$$ \\hat{y} = 2 + x - 0.5x^2 $$ \n",
    "\n",
    "1. What is $\\hat{y}$ at the following values for x?\n",
    "    - $x = -3$\n",
    "    - $x = -1$\n",
    "    - $x = 0$\n",
    "    - $x = 1$\n",
    "    - $x = 3$\n",
    "2. Use Python to check your work for section 1.\n",
    "3. Does $\\hat{y}$ change at a linear rate with $x - 0.5x^2$? Is this useful from a modeling perspective?\n",
    "4. Use `PolynomialFeatures` and the `studytime` feature to create a feature for $\\text{studytime}$ and $\\text{studytime}^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a scatter plot of our training data between `G1` and `G3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1_g3 = df[['G1', 'G3']].values\n",
    "\n",
    "plt.scatter(g1_g3[:, 0], g1_g3[:, 1])\n",
    "plt.xlabel('G1 Values')\n",
    "plt.ylabel('G3 Values')\n",
    "plt.title('G1 v G3 Values, No Scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `MinMaxScaler`, `StandardScaler`, and `RobustScaler` to transform these values and see if visually, there is any difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(g1_g3)\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "ss_scaler.fit(g1_g3)\n",
    "\n",
    "rb_scaler = RobustScaler()\n",
    "rb_scaler.fit(g1_g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm_g1g3 = mm_scaler.transform(g1_g3)\n",
    "\n",
    "plt.scatter(mm_g1g3[:, 0], mm_g1g3[:, 1])\n",
    "plt.xlabel('G1 Values')\n",
    "plt.ylabel('G3 Values')\n",
    "plt.title('G1 v G3 Values, MinMax Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss_g1g3 = ss_scaler.transform(g1_g3)\n",
    "\n",
    "plt.scatter(ss_g1g3[:, 0], ss_g1g3[:, 1])\n",
    "plt.xlabel('G1 Values')\n",
    "plt.ylabel('G3 Values')\n",
    "plt.title('G1 v G3 Values, Standard Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb_g1g3 = rb_scaler.transform(g1_g3)\n",
    "\n",
    "plt.scatter(rb_g1g3[:, 0], rb_g1g3[:, 1])\n",
    "plt.xlabel('G1 Values')\n",
    "plt.ylabel('G3 Values')\n",
    "plt.title('G1 v G3 Values, Robust Scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we could plot all of these on top of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(g1_g3[:, 0], g1_g3[:, 1], \n",
    "            label='Original')\n",
    "plt.scatter(ss_g1g3[:, 0], ss_g1g3[:, 1],\n",
    "           label='Standard')\n",
    "plt.scatter(rb_g1g3[:, 0], rb_g1g3[:, 1],\n",
    "           label='Robust')\n",
    "plt.scatter(mm_g1g3[:, 0], mm_g1g3[:, 1], \n",
    "            label='Minmax')\n",
    "plt.xlabel('G1 Values')\n",
    "plt.ylabel('G3 Values')\n",
    "plt.legend()\n",
    "plt.title('G1 v G3, all scales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, to look at the three scales on top of each other, zoomed-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(g1_g3[:, 0], g1_g3[:, 1], \n",
    "            label='Original')\n",
    "plt.scatter(ss_g1g3[:, 0], ss_g1g3[:, 1],\n",
    "           label='Standard')\n",
    "plt.scatter(rb_g1g3[:, 0], rb_g1g3[:, 1],\n",
    "           label='Robust')\n",
    "plt.scatter(mm_g1g3[:, 0], mm_g1g3[:, 1], \n",
    "            label='Minmax')\n",
    "plt.xlabel('G1 Values')\n",
    "plt.ylabel('G3 Values')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlim(-3, 3)\n",
    "plt.legend()\n",
    "plt.title('G1 v G3, all scales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling will not change the relationship between variables, just the scale that those values are on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the average that is being used for each scaler, the following attributes are stored after fitting. Note that because each scaler is using different ways to get to the same place, each object has different attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(mm_scaler.data_range_, \n",
    "      mm_scaler.data_min_, \n",
    "      mm_scaler.data_max_)\n",
    "print(ss_scaler.mean_, ss_scaler.var_)\n",
    "print(rb_scaler.center_, rb_scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Replicate the plotting and scaling above, this time comparing `age` and `G3` (note, because `age` has missing values, you will need to transform that data first). \n",
    "2. Why would scaling help us understand the relationship between `age` and `G3`?\n",
    "    - One helpful way to think about this is to think about what a one-unit change in each means. How much of the total distribution do you cover if you go up by one unit in `age`? What about for `G3`?\n",
    "3. Apply the standard scaler transformer to the holdout (test) set. \n",
    "4. What is the mean held in the standard scaler object (`ss_scaler.mean_`)?\n",
    "5. What is the mean held in each of the features in the holdout (test) set?\n",
    "6. Are they different? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
